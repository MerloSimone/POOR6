{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil as sh\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'clean_data' created.\n",
      "Folder 'output' created.\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"clean_data\"\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "STATIONS_FILE = \"wa_alt_fuel_stations.csv\"\n",
    "CARS_FILE = \"Electric_Vehicle_Population_Data.csv\"\n",
    "WAGE_FILE = \"20zpallnoagi.csv\"\n",
    "\n",
    "# Get the absolute path\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "try:\n",
    "    # Remove the existing folder\n",
    "    sh.rmtree(DATA_FOLDER)\n",
    "    sh.rmtree(OUTPUT_FOLDER)\n",
    "except FileNotFoundError:\n",
    "    print(\"--- No folder to remove ---\")\n",
    "\n",
    "# Create new folder for clean data\n",
    "os.mkdir(DATA_FOLDER)\n",
    "print(f\"Folder '{DATA_FOLDER}' created.\")\n",
    "os.mkdir(OUTPUT_FOLDER)\n",
    "print(f\"Folder '{OUTPUT_FOLDER}' created.\")\n",
    "\n",
    "DATA_FOLDER += \"\\\\\"\n",
    "OUTPUT_FOLDER += \"\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting and filtering fuel stations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"alt_fuel_stations(Nov-10-2023).csv\", \"r\", encoding=\"utf-8\")                        # Input file\n",
    "wa_fuel_stations = wa_e_stations = open(DATA_FOLDER + STATIONS_FILE, \"w\", encoding=\"utf-8\")     # Output file\n",
    "\n",
    "# Write CSV headers\n",
    "wa_fuel_stations.write(file.readline())\n",
    "\n",
    "row = file.readline()               # Read first line\n",
    "while (row2 := file.readline()):\n",
    "    row2_error = False              \n",
    "\n",
    "    # If the row is interrupted, recover it (there can be multiple interruption)\n",
    "    while(\"ELEC\" not in row2):\n",
    "        row2_error = True\n",
    "        index = row2.find('\",')                                     # Find the end of last interrupted string, if exists\n",
    "        row = row.strip() + row2[index if index != -1 else 0 : ]    # Concatenate the row begin with the second part\n",
    "        row2 = file.readline()\n",
    "\n",
    "    if \",WA,\" in row: wa_e_stations.write(row)\n",
    "    row = row2                                                      # Check on next cycle\n",
    "\n",
    "file.close()\n",
    "wa_e_stations.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import quote\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZIP codes, cities, counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv(\"wa_zips_cities_counties.csv\", sep=\",\")\n",
    "\n",
    "ECO = Namespace(\"http://www.dei.unipd.it/~poor6/db2/ontologies/2023/electricCars#\")\n",
    "\n",
    "graph = Graph()\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 587 µs, total: 144 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in places.iterrows():\n",
    "    ZIP = URIRef(ECO[str(row['Zipcode'])])\n",
    "    City = URIRef(ECO[quote(str(row['City']))])\n",
    "    County = URIRef(ECO[quote(str(row['County']))])\n",
    "\n",
    "    graph.add((ZIP, RDF.type, ECO.ZIP))\n",
    "    graph.add((City, RDF.type, ECO.City))\n",
    "    graph.add((County, RDF.type, ECO.County))\n",
    "\n",
    "    graph.add((ZIP, ECO[\"ofCity\"], City))\n",
    "    graph.add((City, ECO[\"belongsTo\"], County))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 133 ms, sys: 0 ns, total: 133 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'locations.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Washington electrical stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(DATA_FOLDER + STATIONS_FILE, sep=\",\")\n",
    "\n",
    "graph = Graph()\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in ZIP 'G9N 0', skipped\n",
      "CPU times: user 404 ms, sys: 4.18 ms, total: 408 ms\n",
      "Wall time: 406 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in stations.iterrows():\n",
    "    Station = URIRef(ECO[str(index)])     # Create node (prefix + id)\n",
    "\n",
    "    # Triples\n",
    "    graph.add((Station, RDF.type, ECO.Station))\n",
    "    graph.add((Station, ECO['hasName'], Literal(row['Station Name'], datatype=XSD.string)))\n",
    "    \n",
    "    if \" \" in row['ZIP']: \n",
    "        print(f\"Error in ZIP '{row['ZIP']}', skipped\")\n",
    "        continue\n",
    "\n",
    "    ZipCode = URIRef(ECO[row['ZIP']])\n",
    "    graph.add((Station, ECO['locatedIn'], ZipCode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 345 ms, sys: 183 µs, total: 345 ms\n",
      "Wall time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'stations.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150482 entries, 0 to 150481\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                             Non-Null Count   Dtype  \n",
      "---  ------                                             --------------   -----  \n",
      " 0   VIN (1-10)                                         150482 non-null  object \n",
      " 1   County                                             150479 non-null  object \n",
      " 2   City                                               150479 non-null  object \n",
      " 3   State                                              150482 non-null  object \n",
      " 4   Postal Code                                        150479 non-null  float64\n",
      " 5   Model Year                                         150482 non-null  int64  \n",
      " 6   Make                                               150482 non-null  object \n",
      " 7   Model                                              150482 non-null  object \n",
      " 8   Electric Vehicle Type                              150482 non-null  object \n",
      " 9   Clean Alternative Fuel Vehicle (CAFV) Eligibility  150482 non-null  object \n",
      " 10  Electric Range                                     150482 non-null  int64  \n",
      " 11  Base MSRP                                          150482 non-null  int64  \n",
      " 12  Legislative District                               150141 non-null  float64\n",
      " 13  DOL Vehicle ID                                     150482 non-null  int64  \n",
      " 14  Vehicle Location                                   150475 non-null  object \n",
      " 15  Electric Utility                                   150479 non-null  object \n",
      " 16  2020 Census Tract                                  150479 non-null  float64\n",
      "dtypes: float64(3), int64(4), object(10)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "cars = pd.read_csv(CARS_FILE, sep=\",\")\n",
    "cars.info()\n",
    "\n",
    "graph = Graph()      #Graph redefine, so to keep separate working spaces.\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.7 s, sys: 411 ms, total: 50.1 s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#urllib.parse.quote(...)\n",
    "#urllib.parse.unquote(...)\n",
    "\n",
    "for index, row in cars.iterrows():\n",
    "    Car = URIRef(ECO[str(row['DOL Vehicle ID'])])     # Create node (prefix + id)\n",
    "    \n",
    "    EncodedModel = quote(row['Model'])\n",
    "    ModelYear = URIRef(ECO[ EncodedModel + str(row['Model Year']) ])  #2012 'Panda' => Panda2012 <---USO ENC.MOD.\n",
    "    \n",
    "    # Car-instance specific insertions\n",
    "    graph.add((Car, RDF.type, ECO.Car))\n",
    "    graph.add((Car, ECO['hasRange'], Literal(row['Electric Range'], datatype=XSD.integer) ))\n",
    "    graph.add((Car, ECO['hasModelYear'], ModelYear))\n",
    "    \n",
    "    graph.add((ModelYear, RDF.type, ECO.ModelYear))\n",
    "    graph.add((ModelYear, ECO['year'], Literal(row['Model Year'], datatype=XSD.gYear) ))\n",
    "    graph.add((ModelYear, ECO['hasMSRP'], Literal(row['Base MSRP'], datatype=XSD.integer) ))\n",
    "    #Model = URIRef(ECO[row['Model']])\n",
    "    Model = URIRef(ECO[EncodedModel])  #<--- USO ENC.MOD.\n",
    "    graph.add((ModelYear, ECO['ofModel'], Model))\n",
    "    graph.add((Model, RDF.type, ECO.Model))\n",
    "    #Maker = URIRef(ECO[row['Make']])\n",
    "    Maker = URIRef(ECO[quote(row['Make'])])   #<---ENCODED\n",
    "    graph.add((Model, ECO['madeBy'], Maker))\n",
    "    graph.add((Maker, RDF.type, ECO.Maker))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 23.6 s, sys: 80 ms, total: 23.7 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'cars.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage per ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27744 entries, 0 to 27743\n",
      "Columns: 165 entries, STATEFIPS to A12000\n",
      "dtypes: float64(161), int64(3), object(1)\n",
      "memory usage: 34.9+ MB\n"
     ]
    }
   ],
   "source": [
    "salaries = pd.read_csv(WAGE_FILE, sep=\",\")\n",
    "salaries.info()\n",
    "\n",
    "graph = Graph()      #Graph redefine, so to keep separate working spaces.\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 76 ms, total: 2.07 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in salaries.iterrows():\n",
    "    # Exclude non Washington data\n",
    "    if \"WA\" not in row['STATE'] or '98' not in str(row['ZIPCODE']):\n",
    "        continue\n",
    "\n",
    "    Zipcode = URIRef(ECO[str(row['ZIPCODE'])])\n",
    "    \n",
    "    agi = float(row['A00100'])/float(row['N2'])\n",
    "\n",
    "    graph.add((Zipcode, ECO['hasAgi'], Literal(agi, datatype=XSD.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 38.4 ms, sys: 4.03 ms, total: 42.4 ms\n",
      "Wall time: 41.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'agi.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
