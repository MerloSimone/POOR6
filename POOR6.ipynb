{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil as sh\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'clean_data' created.\n",
      "Folder 'output' created.\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"clean_data\"\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "STATIONS_FILE = \"wa_alt_fuel_stations.csv\"\n",
    "CARS_FILE = \"Electric_Vehicle_Population_Data.csv\"\n",
    "WAGE_FILE = \"20zpallnoagi.csv\"\n",
    "\n",
    "# Get the absolute path\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "try:\n",
    "    # Remove the existing folder\n",
    "    sh.rmtree(DATA_FOLDER)\n",
    "    sh.rmtree(OUTPUT_FOLDER)\n",
    "except FileNotFoundError:\n",
    "    print(\"--- No folder to remove ---\")\n",
    "\n",
    "# Create new folder for clean data\n",
    "os.mkdir(DATA_FOLDER)\n",
    "print(f\"Folder '{DATA_FOLDER}' created.\")\n",
    "os.mkdir(OUTPUT_FOLDER)\n",
    "print(f\"Folder '{OUTPUT_FOLDER}' created.\")\n",
    "\n",
    "DATA_FOLDER += \"\\\\\"\n",
    "OUTPUT_FOLDER += \"\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting and filtering fuel stations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"alt_fuel_stations(Nov-10-2023).csv\", \"r\", encoding=\"utf-8\")                        # Input file\n",
    "wa_fuel_stations = wa_e_stations = open(DATA_FOLDER + STATIONS_FILE, \"w\", encoding=\"utf-8\")     # Output file\n",
    "\n",
    "# Write CSV headers\n",
    "wa_fuel_stations.write(file.readline())\n",
    "\n",
    "row = file.readline()               # Read first line\n",
    "while (row2 := file.readline()):\n",
    "    row2_error = False              \n",
    "\n",
    "    # If the row is interrupted, recover it (there can be multiple interruption)\n",
    "    while(\"ELEC\" not in row2):\n",
    "        row2_error = True\n",
    "        index = row2.find('\",')                                     # Find the end of last interrupted string, if exists\n",
    "        row = row.strip() + row2[index if index != -1 else 0 : ]    # Concatenate the row begin with the second part\n",
    "        row2 = file.readline()\n",
    "\n",
    "    if \",WA,\" in row: wa_e_stations.write(row)\n",
    "    row = row2                                                      # Check on next cycle\n",
    "\n",
    "file.close()\n",
    "wa_e_stations.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import quote\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZIP codes, cities, counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv(\"wa_zips_cities_counties.csv\", sep=\",\")\n",
    "\n",
    "ECO = Namespace(\"http://www.dei.unipd.it/~poor6/db2/ontologies/2023/electricCars#\")\n",
    "\n",
    "graph = Graph()\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in places.iterrows():\n",
    "    ZIP = URIRef(ECO[str(row['Zipcode'])])\n",
    "    City = URIRef(ECO[quote(str(row['City']))])\n",
    "    County = URIRef(ECO[quote(str(row['County']))])\n",
    "\n",
    "    graph.add((ZIP, RDF.type, ECO.ZIP))\n",
    "    graph.add((City, RDF.type, ECO.City))\n",
    "    graph.add((County, RDF.type, ECO.County))\n",
    "\n",
    "    graph.add((ZIP, ECO[\"ofCity\"], City))\n",
    "    graph.add((City, ECO[\"belongsTo\"], County))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 34.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'locations.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Washington electrical stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(DATA_FOLDER + STATIONS_FILE, sep=\",\")\n",
    "\n",
    "graph = Graph()\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in stations.iterrows():\n",
    "    Station = URIRef(ECO[str(index)])     # Create node (prefix + id)\n",
    "\n",
    "    # Triples\n",
    "    graph.add((Station, RDF.type, ECO.Station))\n",
    "    graph.add((Station, ECO['hasName'], Literal(row['Station Name'], datatype=XSD.string)))\n",
    "    \n",
    "    if \" \" in row['ZIP']: \n",
    "        print(f\"Error in ZIP '{row['ZIP']}', skipped\")\n",
    "        continue\n",
    "\n",
    "    ZipCode = URIRef(ECO[row['ZIP']])\n",
    "    graph.add((Station, ECO['locatedIn'], ZipCode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'stations.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(CARS_FILE, sep=\",\")\n",
    "cars.info()\n",
    "\n",
    "graph = Graph()      #Graph redefine, so to keep separate working spaces.\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#urllib.parse.quote(...)\n",
    "#urllib.parse.unquote(...)\n",
    "\n",
    "for index, row in cars.iterrows():\n",
    "    Car = URIRef(ECO[str(row['DOL Vehicle ID'])])     # Create node (prefix + id)\n",
    "    \n",
    "    EncodedModel = quote(row['Model'])\n",
    "    ModelYear = URIRef(ECO[ EncodedModel + str(row['Model Year']) ])  #2012 'Panda' => Panda2012 <---USO ENC.MOD.\n",
    "    \n",
    "    # Car-instance specific insertions\n",
    "    graph.add((Car, RDF.type, ECO.Car))\n",
    "    graph.add((Car, ECO['hasRange'], Literal(row['Electric Range'], datatype=XSD.integer) ))\n",
    "    graph.add((Car, ECO['hasModelYear'], ModelYear))\n",
    "    \n",
    "    #Was this ModelYear already defined?\n",
    "    if not graph.value(ModelYear, RDF.type, None):\n",
    "        graph.add((ModelYear, RDF.type, ECO.ModelYear))\n",
    "        graph.add((ModelYear, ECO['year'], Literal(row['Model Year'], datatype=XSD.gYear) ))\n",
    "        graph.add((ModelYear, ECO['hasMSRP'], Literal(row['Base MSRP'], datatype=XSD.integer) ))\n",
    "        #Model = URIRef(ECO[row['Model']])\n",
    "        Model = URIRef(ECO[EncodedModel])  #<--- USO ENC.MOD.\n",
    "        graph.add((ModelYear, ECO['ofModel'], Model))\n",
    "        #Was this model used before?\n",
    "        if not graph.value(Model, RDF.type, None):\n",
    "            graph.add((Model, RDF.type, ECO.Model))\n",
    "            #Maker = URIRef(ECO[row['Make']])\n",
    "            Maker = URIRef(ECO[quote(row['Make'])])   #<---ENCODED\n",
    "            graph.add((Model, ECO['madeBy'], Maker))\n",
    "            #Was this maker already inserted?\n",
    "            if not graph.value(Maker, RDF.type, None):\n",
    "                graph.add((Maker, RDF.type, ECO.Maker)) #OPZIONALMENTE, al posto di check+add usare set(..), metodo analogo ad add ma che non genera triple doppie (con stesso soggetto e predicato sovrascrive oggetto)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'cars.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage per ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27744 entries, 0 to 27743\n",
      "Columns: 165 entries, STATEFIPS to A12000\n",
      "dtypes: float64(161), int64(3), object(1)\n",
      "memory usage: 34.9+ MB\n"
     ]
    }
   ],
   "source": [
    "salaries = pd.read_csv(WAGE_FILE, sep=\",\")\n",
    "salaries.info()\n",
    "\n",
    "graph = Graph()      #Graph redefine, so to keep separate working spaces.\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 531 ms\n",
      "Wall time: 526 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in salaries.iterrows():\n",
    "    # Exclude non Washington data\n",
    "    if \"WA\" not in row['STATE'] or '98' not in str(row['ZIPCODE']):\n",
    "        continue\n",
    "\n",
    "    Zipcode = URIRef(ECO[str(row['ZIPCODE'])])\n",
    "    \n",
    "    agi = float(row['A00100'])/float(row['N2'])\n",
    "\n",
    "    graph.add((Zipcode, ECO['hasAgi'], Literal(agi, datatype=XSD.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 9.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'agi.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
