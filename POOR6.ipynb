{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POOR6\n",
    "\n",
    "Group project of the \"Database 2\" course, Computer Engineering MD, Universit√† degli Studi di Padova, a.a. 2023/24, by the POOR6 group: Merlo Simone, Gobbo Riccardo, Spinosa Diego.\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "We have chosen to work on three tightly linked **datasets**:\n",
    " - \"*Electric Vehicle Population Data*\" provided by the Dept. of Licensing of the State of Washington, US. This dataset shows the Battery Electric Vehicles (BEVs) and Plug-in Hybrid Electric Vehicles (PHEVs) that are currently registered through Washington State Department of Licensing (DOL).  [source](https://data.wa.gov/Transportation/Electric-Vehicle-Population-Data/f6w7-q2d2)\n",
    " - \"*Alternative Fuel Stations*\", as part of the Alternative Fuels Data Center of the U.S. Department of Energy. This dataset was used to obtain location and properties of all the registered EV charging stations in the state of Washington. [source](https://afdc.energy.gov/data_download/alt_fuel_stations_format)\n",
    " - \"*SOI Tax Stats - Individual Income Tax Statistics*\" provided by the IRS (Internal Revenue Service) of the US. Data are based on individual income tax returns filed with the IRS and are used to determine how the average income varies among Washington's zipcodes. [source](https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-2020-zip-code-data-soi)\n",
    "\n",
    "The project aims at linking these 3 data sources to discover whether there are some interesting correlations between EV diffusion, EV charging station density and average income in the scope of the territory of state of Washington. We are focusing on this region since we have found a particularly good data quality and availability, and also because its scenario can resemble the one found in most other US states or even other first world countries worldwide.\n",
    "\n",
    "In order to properly link these datasets we exploited a fourth data source that provided us data regarding the ZipCodes of the state of Washington."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES:\n",
    "In our domain we assumed that each ZipCode is related to one and one only city, in the reality a ZipCodes can span over multiple cities but each of them has a \"primary city\". We considered the \"primary city\" as the only city related to a particular ZipCode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil as sh\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions definition\n",
    "Defining a function to turn text strings in something usable for IRIs.\n",
    "In particular we first map the string's characters to ASCII only characters, then we convert the string in Camel-case notation and eventually we remove spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urify_string(s: str):\n",
    "    s=unidecode(s)\n",
    "    pattern = \"[^0-9a-zA-Z\\s]+\"\n",
    "    s = re.sub(pattern, \" \", s).title().replace(\" \", \"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary operations\n",
    "\n",
    "Creating paths and folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'clean_data' created.\n",
      "Folder 'output' created.\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"clean_data\"\n",
    "SOURCE_FOLDER = \"src_data/\"\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "STATIONS_FILE = \"stations_pub+priv_open.csv\"\n",
    "LOCATIONS = SOURCE_FOLDER + \"wa_zips_cities_counties.csv\"\n",
    "CARS_FILE = SOURCE_FOLDER + \"Electric_Vehicle_Population_Data.csv\"\n",
    "WAGE_FILE = SOURCE_FOLDER + \"20zpallnoagi.csv\"\n",
    "\n",
    "# Get the absolute path\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "try:\n",
    "    # Remove the existing folder\n",
    "    sh.rmtree(DATA_FOLDER)\n",
    "    sh.rmtree(OUTPUT_FOLDER)\n",
    "except FileNotFoundError:\n",
    "    print(\"--- No folder to remove ---\")\n",
    "\n",
    "# Create new folder for clean data\n",
    "os.mkdir(DATA_FOLDER)\n",
    "print(f\"Folder '{DATA_FOLDER}' created.\")\n",
    "os.mkdir(OUTPUT_FOLDER)\n",
    "print(f\"Folder '{OUTPUT_FOLDER}' created.\")\n",
    "\n",
    "DATA_FOLDER += \"/\"\n",
    "OUTPUT_FOLDER += \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting and filtering fuel stations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(SOURCE_FOLDER + STATIONS_FILE, \"r\", encoding=\"utf-8\")                  # Input file\n",
    "wa_fuel_stations = wa_e_stations = open(DATA_FOLDER + STATIONS_FILE, \"w\", encoding=\"utf-8\")     # Output file\n",
    "\n",
    "# Write CSV headers\n",
    "wa_fuel_stations.write(file.readline())\n",
    "\n",
    "row = file.readline()               # Read first line\n",
    "while (row2 := file.readline()):\n",
    "    row2_error = False              \n",
    "\n",
    "    # If the row is interrupted, recover it (there can be multiple interruption)\n",
    "    while(\"ELEC\" not in row2):\n",
    "        row2_error = True\n",
    "        index = row2.find('\",')                                     # Find the end of last interrupted string, if exists\n",
    "        row = row.strip() + row2[index if index != -1 else 0 : ]    # Concatenate the row begin with the second part\n",
    "        row2 = file.readline()\n",
    "\n",
    "    if \",WA,\" in row: wa_e_stations.write(row)\n",
    "    row = row2                                                      # Check on next cycle\n",
    "\n",
    "file.close()\n",
    "wa_e_stations.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import quote\n",
    "from rdflib import Graph, Literal, RDF, RDFS, URIRef, Namespace\n",
    "from rdflib.namespace import XSD\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZipCode codes, cities, counties\n",
    "Reading the ZipCode file and creating the triples related to ZipCodes,Cities and Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv(LOCATIONS, sep=\",\")\n",
    "\n",
    "ECO = Namespace(\"http://www.dei.unipd.it/~poor6/db2/ontologies/2023/electricCars#\")\n",
    "\n",
    "graph = Graph()\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in places.iterrows():\n",
    "    #Creating the URIs using the urify_string function\n",
    "    ZipCode = URIRef(ECO[str(row['Zipcode'])])\n",
    "    City = URIRef(ECO[urify_string(str(row['City']))])\n",
    "    County = URIRef(ECO[urify_string(str(row['County']))])\n",
    "\n",
    "    graph.add((ZipCode, RDF.type, ECO.ZipCode)) #Adding ZipCodes\n",
    "    graph.add((City, RDF.type, ECO.City)) #Adding City\n",
    "    graph.add((County, RDF.type, ECO.County)) #Adding County\n",
    "    \n",
    "    #Adding labels to keep the original strings\n",
    "    graph.add((City, RDFS.label, Literal(str(row['City']), datatype=XSD.string)))\n",
    "    graph.add((County, RDFS.label, Literal(str(row['County']), datatype=XSD.string)))\n",
    "\n",
    "    #Adding relations\n",
    "    graph.add((ZipCode, ECO[\"ofCity\"], City))\n",
    "    graph.add((City, ECO[\"belongsTo\"], County))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 98.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'locations.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Washington electrical stations\n",
    "\n",
    "Reading the Electric StationsZip file and creating the triples related to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2188 entries, 0 to 2187\n",
      "Data columns (total 74 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   Fuel Type Code                           2188 non-null   object \n",
      " 1   Station Name                             2188 non-null   object \n",
      " 2   Street Address                           2185 non-null   object \n",
      " 3   Intersection Directions                  109 non-null    object \n",
      " 4   City                                     2188 non-null   object \n",
      " 5   State                                    2188 non-null   object \n",
      " 6   ZIP                                      2188 non-null   object \n",
      " 7   Plus4                                    0 non-null      float64\n",
      " 8   Station Phone                            2028 non-null   object \n",
      " 9   Status Code                              2188 non-null   object \n",
      " 10  Expected Date                            0 non-null      float64\n",
      " 11  Groups With Access Code                  2188 non-null   object \n",
      " 12  Access Days Time                         1952 non-null   object \n",
      " 13  Cards Accepted                           121 non-null    object \n",
      " 14  BD Blends                                0 non-null      float64\n",
      " 15  NG Fill Type Code                        0 non-null      float64\n",
      " 16  NG PSI                                   0 non-null      float64\n",
      " 17  EV Level1 EVSE Num                       57 non-null     float64\n",
      " 18  EV Level2 EVSE Num                       1951 non-null   float64\n",
      " 19  EV DC Fast Count                         274 non-null    float64\n",
      " 20  EV Other Info                            2 non-null      object \n",
      " 21  EV Network                               2188 non-null   object \n",
      " 22  EV Network Web                           1853 non-null   object \n",
      " 23  Geocode Status                           2188 non-null   object \n",
      " 24  Latitude                                 2188 non-null   float64\n",
      " 25  Longitude                                2188 non-null   float64\n",
      " 26  Date Last Confirmed                      2174 non-null   object \n",
      " 27  ID                                       2188 non-null   int64  \n",
      " 28  Updated At                               2188 non-null   object \n",
      " 29  Owner Type Code                          510 non-null    object \n",
      " 30  Federal Agency ID                        104 non-null    float64\n",
      " 31  Federal Agency Name                      104 non-null    object \n",
      " 32  Open Date                                2187 non-null   object \n",
      " 33  Hydrogen Status Link                     0 non-null      float64\n",
      " 34  NG Vehicle Class                         0 non-null      float64\n",
      " 35  LPG Primary                              0 non-null      float64\n",
      " 36  E85 Blender Pump                         0 non-null      float64\n",
      " 37  EV Connector Types                       2188 non-null   object \n",
      " 38  Country                                  2188 non-null   object \n",
      " 39  Intersection Directions (French)         0 non-null      float64\n",
      " 40  Access Days Time (French)                0 non-null      float64\n",
      " 41  BD Blends (French)                       0 non-null      float64\n",
      " 42  Groups With Access Code (French)         2188 non-null   object \n",
      " 43  Hydrogen Is Retail                       0 non-null      float64\n",
      " 44  Access Code                              2188 non-null   object \n",
      " 45  Access Detail Code                       145 non-null    object \n",
      " 46  Federal Agency Code                      104 non-null    object \n",
      " 47  Facility Type                            493 non-null    object \n",
      " 48  CNG Dispenser Num                        0 non-null      float64\n",
      " 49  CNG On-Site Renewable Source             0 non-null      float64\n",
      " 50  CNG Total Compression Capacity           0 non-null      float64\n",
      " 51  CNG Storage Capacity                     0 non-null      float64\n",
      " 52  LNG On-Site Renewable Source             0 non-null      float64\n",
      " 53  E85 Other Ethanol Blends                 0 non-null      float64\n",
      " 54  EV Pricing                               551 non-null    object \n",
      " 55  EV Pricing (French)                      0 non-null      float64\n",
      " 56  LPG Nozzle Types                         0 non-null      float64\n",
      " 57  Hydrogen Pressures                       0 non-null      float64\n",
      " 58  Hydrogen Standards                       0 non-null      float64\n",
      " 59  CNG Fill Type Code                       0 non-null      float64\n",
      " 60  CNG PSI                                  0 non-null      float64\n",
      " 61  CNG Vehicle Class                        0 non-null      float64\n",
      " 62  LNG Vehicle Class                        0 non-null      float64\n",
      " 63  EV On-Site Renewable Source              10 non-null     object \n",
      " 64  Restricted Access                        306 non-null    object \n",
      " 65  RD Blends                                0 non-null      float64\n",
      " 66  RD Blends (French)                       0 non-null      float64\n",
      " 67  RD Blended with Biodiesel                0 non-null      float64\n",
      " 68  RD Maximum Biodiesel Level               0 non-null      float64\n",
      " 69  NPS Unit Name                            13 non-null     object \n",
      " 70  CNG Station Sells Renewable Natural Gas  0 non-null      float64\n",
      " 71  LNG Station Sells Renewable Natural Gas  0 non-null      float64\n",
      " 72  Maximum Vehicle Class                    283 non-null    object \n",
      " 73  EV Workplace Charging                    2188 non-null   bool   \n",
      "dtypes: bool(1), float64(39), int64(1), object(33)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "stations = pd.read_csv(DATA_FOLDER + STATIONS_FILE, sep=\",\")\n",
    "\n",
    "stations.info()\n",
    "\n",
    "graph = Graph()\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in ZIP 'G9N 0', skipped\n",
      "CPU times: total: 453 ms\n",
      "Wall time: 453 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in stations.iterrows():\n",
    "    Station = URIRef(ECO[str(index)])     # Create node (prefix + incremental id)\n",
    "\n",
    "    #Adding the statio type (private or public)\n",
    "    if(re.search(\".*[Pp]rivate.*\",row['Access Code'])):\n",
    "        graph.add((Station, RDF.type, ECO.PrivateStation))\n",
    "    elif (re.search(\".*[Pp]ublic.*\",row['Access Code'])):\n",
    "        graph.add((Station, RDF.type, ECO.PublicStation))\n",
    "    \n",
    "    graph.add((Station, RDF.type, ECO.Station))             \n",
    "\n",
    "    # Adding station name and address if present\n",
    "    graph.add((Station, ECO['hasName'], Literal(row['Station Name'], datatype=XSD.string)))\n",
    "    if row['Street Address']:\n",
    "        graph.add((Station, ECO['hasAddress'], Literal(row['Street Address'], datatype=XSD.string)))\n",
    "    \n",
    "    latitude = None\n",
    "    longitude = None\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "\n",
    "    if latitude is not None and longitude is not None:\n",
    "        graph.add((Station, ECO['hasLatitude'], Literal(row['Latitude'], datatype=XSD.float)))\n",
    "        graph.add((Station, ECO['hasLongitude'], Literal(row['Longitude'], datatype=XSD.float)))\n",
    "\n",
    "    #Avoiding strange cases\n",
    "    if \" \" in row['ZIP']: \n",
    "        print(f\"Error in ZIP '{row['ZIP']}', skipped\")\n",
    "        continue\n",
    "\n",
    "    #Linking a station to its ZipCode\n",
    "    ZipCode = URIRef(ECO[row['ZIP']])\n",
    "    graph.add((Station, ECO['locatedIn'], ZipCode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 375 ms\n",
      "Wall time: 375 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'stations.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars\n",
    "Reading the cars file and creating the triples related to them. This includes the creation of cars, models, makers and model-years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150482 entries, 0 to 150481\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                             Non-Null Count   Dtype  \n",
      "---  ------                                             --------------   -----  \n",
      " 0   VIN (1-10)                                         150482 non-null  object \n",
      " 1   County                                             150479 non-null  object \n",
      " 2   City                                               150479 non-null  object \n",
      " 3   State                                              150482 non-null  object \n",
      " 4   Postal Code                                        150479 non-null  float64\n",
      " 5   Model Year                                         150482 non-null  int64  \n",
      " 6   Make                                               150482 non-null  object \n",
      " 7   Model                                              150482 non-null  object \n",
      " 8   Electric Vehicle Type                              150482 non-null  object \n",
      " 9   Clean Alternative Fuel Vehicle (CAFV) Eligibility  150482 non-null  object \n",
      " 10  Electric Range                                     150482 non-null  int64  \n",
      " 11  Base MSRP                                          150482 non-null  int64  \n",
      " 12  Legislative District                               150141 non-null  float64\n",
      " 13  DOL Vehicle ID                                     150482 non-null  int64  \n",
      " 14  Vehicle Location                                   150475 non-null  object \n",
      " 15  Electric Utility                                   150479 non-null  object \n",
      " 16  2020 Census Tract                                  150479 non-null  float64\n",
      "dtypes: float64(3), int64(4), object(10)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "cars = pd.read_csv(CARS_FILE, sep=\",\")\n",
    "cars.info()\n",
    "\n",
    "graph = Graph()      #Graph redefine, so to keep separate working spaces.\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.8 s\n",
      "Wall time: 50.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "for index, row in cars.iterrows():\n",
    "    \n",
    "    #Skipping cars that are outside washington state (if present)\n",
    "    if('WA' != row['State']):\n",
    "        continue\n",
    "        \n",
    "    Car = URIRef(ECO[str(row['DOL Vehicle ID'])])     # Create car based on the DOL \n",
    "    \n",
    "    #Creting a string ready to be turned into a uri\n",
    "    SpacelessModel = urify_string(row['Model'])\n",
    "    \n",
    "    #Creatign modelYear\n",
    "    ModelYear = URIRef(ECO[ SpacelessModel + str(row['Model Year']) ])  #2012 'Grand Cherokee' => GrandCherokee2012\n",
    "    \n",
    "    #Linking a car to its ZipCode\n",
    "    ZipCode = URIRef(ECO[str(int(row['Postal Code']))])\n",
    "    graph.add((Car, ECO['isRegisteredIn'], ZipCode))\n",
    "    \n",
    "    # If there are valid coordinates\n",
    "    if (row['Vehicle Location'] is not None) and (point := re.findall(\"(?<=\\().*(?=\\))\", str(row['Vehicle Location']))):\n",
    "        coordinates = point.pop().split()\n",
    "        latitude = coordinates.pop()\n",
    "        longitude = coordinates.pop()\n",
    "        # Cars' coordinates represent the ZipCode centers, hence when these information is retrieved, it's added to the corresponding ZipCode\n",
    "        graph.add((ZipCode, ECO['hasLongitude'], Literal(longitude, datatype=XSD.float)))\n",
    "        graph.add((ZipCode, ECO['hasLatitude'], Literal(latitude, datatype=XSD.float)))\n",
    "\n",
    "    # Car-instance specific insertions\n",
    "    \n",
    "    graph.add((Car, RDF.type, ECO.Car))\n",
    "    graph.add((Car, ECO['hasVIN'], Literal(row['VIN (1-10)'], datatype=XSD.string) ))\n",
    "        \n",
    "    \n",
    "    #Adding car type (BEV/PHEV or CleanCar/NotCleanCar)\n",
    "    if(re.search(\".*BEV.*\",row['Electric Vehicle Type'])):\n",
    "        graph.add((Car, RDF.type, ECO.CleanCar))\n",
    "        graph.add((Car, RDF.type, ECO.BEV))\n",
    "    else:\n",
    "        graph.add((Car, RDF.type, ECO.PHEV))\n",
    "        if ((row['Electric Range'] >0) and (row['Electric Range'] <30)):\n",
    "            graph.add((Car, RDF.type, ECO.NotCleanCar))\n",
    "        elif ((row['Electric Range'] >=30)):\n",
    "            graph.add((Car, RDF.type, ECO.CleanCar))\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    #Adding range only if maintained (grater than zero)\n",
    "    if (row['Electric Range'] > 0):\n",
    "        graph.add((Car, ECO['hasRange'], Literal(row['Electric Range'], datatype=XSD.integer) ))\n",
    "    \n",
    "    graph.add((Car, ECO['hasModelYear'], ModelYear))\n",
    "    \n",
    "    graph.add((ModelYear, RDF.type, ECO.ModelYear))\n",
    "    graph.add((ModelYear, ECO['hasYear'], Literal(row['Model Year'], datatype=XSD.gYear) ))\n",
    "    \n",
    "    #Adding MSRP only if maintained\n",
    "    if (row['Base MSRP'] > 0):\n",
    "        graph.add((ModelYear, ECO['hasMSRP'], Literal(row['Base MSRP'], datatype=XSD.integer) ))\n",
    "    \n",
    "    Model = URIRef(ECO[SpacelessModel])  #<--- uri-ready string defined before\n",
    "    graph.add((Model, RDFS.label, Literal(row['Model'], datatype=XSD.string))) #LABEL: TO SAVE ORIG. SPACED MODEL\n",
    "    graph.add((ModelYear, ECO['ofModel'], Model))\n",
    "    graph.add((Model, RDF.type, ECO.Model))\n",
    " \n",
    "    Maker = URIRef(ECO[urify_string(row['Make'])])   #<--- spaceless uri also for maker (ex. \"Aston Martin\")\n",
    "    graph.add((Maker, RDFS.label, Literal(row['Make'], datatype=XSD.string))) #LABEL: TO SAVE ORIG. SPACED MAKER\n",
    "    graph.add((Model, ECO['madeBy'], Maker))\n",
    "    graph.add((Maker, RDF.type, ECO.Maker))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 24.9 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'cars.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage per ZIP code\n",
    "Reading the AGI file and creating the triples related to AGI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27744 entries, 0 to 27743\n",
      "Columns: 165 entries, STATEFIPS to A12000\n",
      "dtypes: float64(161), int64(3), object(1)\n",
      "memory usage: 34.9+ MB\n"
     ]
    }
   ],
   "source": [
    "salaries = pd.read_csv(WAGE_FILE, sep=\",\")\n",
    "salaries.info()\n",
    "\n",
    "graph = Graph()      #Graph redefine, so to keep separate working spaces.\n",
    "graph.bind(\"elec\", ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 766 ms\n",
      "Wall time: 797 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in salaries.iterrows():\n",
    "    # Exclude non Washington data\n",
    "    if \"WA\" not in row['STATE'] or '00000' in str(row['ZIPCODE']) or '99999' in str(row['ZIPCODE']) or '0' == str(row['ZIPCODE']):\n",
    "        continue\n",
    "\n",
    "    Zipcode = URIRef(ECO[str(row['ZIPCODE'])])\n",
    "    \n",
    "    agi = int(((row['A00100'])/float(row['N2'])) * 1000)\n",
    "\n",
    "    graph.add((Zipcode, ECO['hasAgi'], Literal(agi, datatype=XSD.int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 25.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(OUTPUT_FOLDER + 'agi.ttl', 'w') as file:\n",
    "    file.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
